---
title: 神经网络学习笔记4：使用 LM Studio 部署大语言模型
date: 2025-06-05 18:44:53
categories:
- 神经网络与深度学习
---

本地部署大语言模型具有自由度高的优势，可以下载各种微调过的模型，或者通过特定的提示词构建属于自己的智能体。本文记录了使用 LM Studio 部署 DeepSeek R1 模型的完整流程与实测结果，以供参考。

<!-- more -->

## 系统配置

我使用的电脑配置如下：

- CPU：AMD 7600X
- 内存：32GB DDR5
- GPU：Nvidia RTX 4070（12GB 显存）

## 模型选择与量化策略

近期，DeepSeek发布了R1版本，在推理能力方面进步显著。但原版模型过于庞大，显然不能部署在这样的电脑中，因此需要“蒸馏”与“量化”。蒸馏是一种模型压缩技术，通过让小模型学习大模型的输出行为，以在保持性能的同时显著减少模型规模；而量化是将模型参数从高精度浮点数压缩为低精度浮点数或整型的过程，可以降低内存占用和加速推理速度。

通过查阅资料，我在 Hugging Face 中选择了 [unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF) 模型，这个项目名称的含义如下：

- `unsloth`：本身是一个专注于大语言模型微调与推理优化的开源项目，此处表示这是其团队发布的量化版本
- `DeepSeek-R1-0528`：原模型，作为蒸馏过程中的“老师”
- `Qwen3`：是阿里巴巴研发的大语言模型之一，作为蒸馏过程中的“学生”
- `8B`：参数量，表示有 80 亿个参数，属于中等规模的大语言模型
- `GGUF`：一种为 GGML 推理框架设计的高效文件格式，支持量化并可被 LM Studio 等工具直接加载

这个项目提供了从 16bit 到 1bit 的量化精度，查阅资料可知，为了保持模型精度，一般不低于 4bit 量化。下载 5bit 模型后，通过调整参数可以勉强运行，但每秒生成 token 的速度较低，存在明显延迟。相比之下，4bit 量化速度显著提升，内存占用降低，更适合 12GB 显存显卡的部署需求，因此最终选择 4bit 模型文件继续部署。

## 模型加载参数设置

在 LM Studio 的模型加载界面，需要根据硬件配置调整参数，以保证运行效率和对话能力。这一过程中可能遇到多次加载失败的情况，一般都是设置的参数过于激进以至于超出内存或显存的承载能力，只需降低对应参数即可。

- `Context Length`：设置为 8192。该参数决定了模型在生成时可参考的历史对话长度。较大的值可以提升对话的连续性和上下文理解能力，但也显著增加显存需求。实测发现，8192 是兼顾性能与可用性的上限
- `GPU Offload`：设置为 43。该参数用于指定多少层模型权重由 GPU 处理。值越大，推理速度越快，但显存压力也越大。在 12GB 显存下，43 层是一个较为稳定的配置，再高可能导致 OOM（显存溢出）
- `Keep Model In Memory`：关闭。默认开启此项可以在模型被卸载后快速重新加载，但会持续占用内存。在内存总量仅为32GB的系统上，关闭此项可以避免无谓的资源占用
- 其余参数：保持默认设置

为了获得理想的输出质量，还需在右侧 `Settings` 选项卡中对生成策略进行微调：

- `Temperature`：设置为 0.6。控制输出的随机性。数值越低，模型越保守，越高则越具有创造性。0.6 是一个平衡点，可以避免“胡言乱语”的情况，又不至于生成重复答案。
- `top-p`：设置为 0.95。与 top_k 配合用于控制输出多样性。0.95 表示模型在最有可能的前95%概率词中采样，能保证内容连贯性与一定的创造性。
- `top_k`：保持默认（通常为40或0，视模型设置）

## 模型能力测试

如果一切顺利，加载进度条到底后模型就成功加载。在对话框中输入如下内容以检测模型的推理和回答能力：

```
下面是一段笔记，关于论文写作，用中文拼音记录，需要你将其还原成汉字。

10cankao+2-3zuixin
beijing+chuzhong+cunzaiwenti+zhenduiwenti,tichujiejuefangan
sheji yunxinliucheng xitongjiegou
shiyan A,B,C
```

得到如下内容：

```
<think>
嗯，用户发来了一段拼音笔记，需要我把它还原成汉字。首先，我要仔细看看这段内容是什么。看起来像是论文写作的笔记，结构有点复杂。

第一句是“10cankao+2-3zuixin”。这里，“cankao”应该是参考的意思，而“zuixin”是最新。所以可能是“参考文献10篇，引用2-3个最新资料”？或者是参考文献的数量和引用次数？

接下来是“beijing+chuzhong+cunzhuwenti+zhenduiwenti,tichujiejuefangan”。这几个词分开来看，“beijing”是背景，“chuzhong”可能是初种或者处理，不太确定。“cunzhuwenti”应该是存在问题，“zhenduiwenti”是针对问题。后面的是“tichujiejuefangan”，提出来解决方法。所以这部分可能需要重组，比如分析现状、存在的问题，以及针对这些问题提出解决方案。

然后是“sheji yunxinliucheng xitongjiegou”。这里应该是设计云信息流程系统结构，看起来像是论文中的一个部分，关于系统设计的内容。

最后一句是“shiyan A,B,C”，这可能是指实验A、B、C三个部分或者步骤。

整体来看，用户可能是在整理论文的提纲或笔记，需要把这些拼音转换成有意义的中文句子。我应该确保每个部分都准确还原，并且保持逻辑连贯。特别是第二部分可能有些词拆分不太清楚，比如“chuzhong”是否正确，需要确认是否是“初种”或者其他意思。

另外，用户可能是学生或研究者，在写论文时记录了这些笔记，现在需要将它们转化为正式的中文内容。因此，回复时要准确，并且结构清晰，方便他们继续撰写论文。
</think>



参考文献10篇，引用2-3个最新资料  
分析现状、存在问题及针对问题提出解决方法  
设计云信息流程系统结构  
实验A、B、C
```

可见模型工作正常，至此部署完成。